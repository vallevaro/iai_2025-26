{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP37GES54jLmg2+om+M5EW/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#CDIA:::AAI - Greedy Best-First Search Methods-- SHORTEST PATH PROBLEM\n","\n","Ibai Laña\n","\n","In this notebook we will write a generalized version of Greedy Best First Search methods that can work with any problem once it is formulated. Then, the key of the solution will be generating proper problem formulations and the proper heuristic function.\n","\n","\n","## Frontier operation Functions\n","In GBFS methods the extraction is not based on their arrival to the queue order, but on the similarity to the heuristic function.\n","\n","\n","\n","## PROBLEM FORMULATION\n","The problem was formulated as a Python class, with the actions, restrictions and functions integrated and always the same name, so they can be re-coded for different problems and the search methods work the same. We start creating the class for River crossing problem. Creating other problems will only require changing some parts of this class.\n","\n","In this NB we will follow with SPP\n"],"metadata":{"id":"bOfVtId4e4hm"}},{"cell_type":"code","source":["import numpy as np\n","class spp ():\n","    #attributes of the class are empty\n","    name = \"\"\n","    initial_state = {}\n","    goal_state = {}\n","    actions = []\n","    connections = {}\n","\n","    def __init__(self): ## init method is the constructor.\n","        self.name =\"SPP\"\n","        self.initial_state = \"Arad\"\n","        self.goal_state = \"Bucharest\"\n","        self.actions=[\"Arad\", \"Bucharest\", \"Craiova\", \"Dobreta\", \"Eforie\",\n","                      \"Fagaras\", \"Giurgiu\", \"Hirsova\", \"Iasi\", \"Lugoj\",\n","                      \"Mehadia\", \"Neamt\", \"Oradea\", \"Pitesti\", \"RimnicuVilcea\",\n","                      \"Sibiu\", \"Timisoara\", \"Urziceni\", \"Vaslui\", \"Zerind\"]\n","        #how do we code information about distances or air_distance to bucharesT??\n","\n","        self.connections={\n","                \"Arad\":{\"actions\":{\"Zerind\": 75,\"Sibiu\": 140,\"Timisoara\": 118},\n","                      \t\"air_distance_to_bucharest\": 366},\n","                 \"Bucharest\":{\"actions\":{\"Fagaras\": 211,\"Giurgiu\": 90,\"Pitesti\": 101,\"Urziceni\": 85},\n","\t\t\t\t\t\t\t\t\"air_distance_to_bucharest\": 0},\n","                \"Craiova\":{\"actions\":{\"Dobreta\": 120,\"Pitesti\": 138,\"RimnicuVilcea\": 146},\n","\t\t\t\t\t\t\t\t\"air_distance_to_bucharest\": 160},\n","                \"Dobreta\":{\"actions\":{\"Mehadia\": 75,\"Craiova\": 120},\n","\t\t\t\t\t\t\t\t\"air_distance_to_bucharest\": 242},\n","                \"Eforie\":{\"actions\":{\"Hirsova\": 86},\n","\t\t\t\t\t\t\t\t\"air_distance_to_bucharest\": 161},\n","                \"Fagaras\":{\"actions\":{\"Sibiu\": 99,\"Bucharest\": 211},\n","\t\t\t\t\t\t\t\t\"air_distance_to_bucharest\": 178},\n","                \"Giurgiu\":{\"actions\":{\"Bucharest\": 90},\n","\t\t\t\t\t\t\t\t\"air_distance_to_bucharest\": 77},\n","                \"Hirsova\":{\"actions\":{\"Eforie\": 86,\"Urziceni\": 98},\n","\t\t\t\t\t\t\t\t\"air_distance_to_bucharest\": 151},\n","                \"Iasi\":{\"actions\":{\"Neamt\": 87,\"Vaslui\": 92},\n","\t\t\t\t\t\t\t\t\"air_distance_to_bucharest\": 226},\n","                \"Lugoj\":{\"actions\":{\"Timisoara\": 111,\"Mehadia\": 70},\n","\t\t\t\t\t\t\t\t\"air_distance_to_bucharest\": 244},\n","                \"Mehadia\":{\"actions\":{\"Lugoj\": 70,\"Dobreta\": 75},\n","\t\t\t\t\t\t\t\t\"air_distance_to_bucharest\": 241},\n","                \"Neamt\":{\"actions\":{\"Iasi\": 87},\n","\t\t\t\t\t\t\t\t\"air_distance_to_bucharest\": 234},\n","                \"Oradea\":{\"actions\":{\"Sibiu\": 151,\"Zerind\": 71},\n","\t\t\t\t\t\t\t\t\"air_distance_to_bucharest\": 380},\n","                \"Pitesti\":{\"actions\":{\"Craiova\": 138,\"Bucharest\": 101,\"RimnicuVilcea\": 97},\n","\t\t\t\t\t\t\t\t\"air_distance_to_bucharest\": 98},\n","                \"RimnicuVilcea\":{\"actions\":{\"Craiova\": 146,\"Pitesti\": 97,\"Sibiu\": 80},\n","\t\t\t\t\t\t\t\t\"air_distance_to_bucharest\": 193},\n","                \"Sibiu\":{\"actions\":{\"Oradea\": 151,\"Arad\": 140,\"Fagaras\": 99,\"RimnicuVilcea\": 80},\n","\t\t\t\t\t\t\t\t\"air_distance_to_bucharest\": 253},\n","                \"Timisoara\":{\"actions\":{\"Arad\": 118,\"Lugoj\": 111},\n","\t\t\t\t\t\t\t\t\"air_distance_to_bucharest\": 329},\n","                \"Urziceni\":{\"actions\":{\"Hirsova\": 98,\"Bucharest\": 85,\"Vaslui\": 142},\n","\t\t\t\t\t\t\t\t\"air_distance_to_bucharest\": 80},\n","                \"Vaslui\":{\"actions\":{\"Iasi\": 92,\"Urziceni\": 142},\n","\t\t\t\t\t\t\t\t\"air_distance_to_bucharest\": 199},\n","                \"Zerind\":{\"actions\":{\"Arad\": 75,\"Oradea\": 71},\n","\t\t\t\t\t\t\t\t\"air_distance_to_bucharest\": 374}}\n","\n","\n","\n","\n","    def is_final_state(self, state):\n","      return state == self.goal_state\n","\n","\n","    #####\n","    def is_applicable (self, state, action):\n","      return action in self.connections[state][\"actions\"].keys()\n","\n","\n","\n","    # moving to another city results in being in this city.\n","    def effect (self, state, action):\n","      return action\n","\n","\n","\n","  ## NOW COST AND EVALUATION ARE RELEVANT.\n","  ## EVALUATION IS THE HEURISTIC FUNCTION THAT WILL SAY HOW SIMILAR IS A SOLUTION TO FINAL ONE.\n","  ### in this case COST is path cost\n","    def get_cost(self, action, state):\n","        #the distance to the city is encoded in the connections dict.\n","        return self.connections[state][\"actions\"][action]\n","\n","\n","  ### but the evaluation should be some function that tells us how different is the solution\n","\n","    def get_evaluation (self, state):\n","      # we don't know the real distance, so we use a straight distance table.\n","      return self.connections[state][\"air_distance_to_bucharest\"]\n","\n"],"metadata":{"id":"V-8WpRt7ff42"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["connections={ \"Arad\":{\"actions\":{\"Zerind\": 75,\"Sibiu\": 140,\"Timisoara\": 118},\n","                      \t\"air_distance_to_bucharest\": 366},\n","                 \"Bucharest\":{\"actions\":{\"Fagaras\": 211,\"Giurgiu\": 90,\"Pitesti\": 101,\"Urziceni\": 85},\n","\t\t\t\t\t\t\t\t\"air_distance_to_bucharest\": 0},\n","                \"Craiova\":{\"actions\":{\"Dobreta\": 120,\"Pitesti\": 138,\"RimnicuVilcea\": 146},\n","\t\t\t\t\t\t\t\t\"air_distance_to_bucharest\": 160},\n","                \"Dobreta\":{\"actions\":{\"Mehadia\": 75,\"Craiova\": 120},\n","\t\t\t\t\t\t\t\t\"air_distance_to_bucharest\": 242},\n","                \"Eforie\":{\"actions\":{\"Hirsova\": 86},\n","\t\t\t\t\t\t\t\t\"air_distance_to_bucharest\": 161},\n","                \"Fagaras\":{\"actions\":{\"Sibiu\": 99,\"Bucharest\": 211},\n","\t\t\t\t\t\t\t\t\"air_distance_to_bucharest\": 178},\n","                \"Giurgiu\":{\"actions\":{\"Bucharest\": 90},\n","\t\t\t\t\t\t\t\t\"air_distance_to_bucharest\": 77},\n","                \"Hirsova\":{\"actions\":{\"Eforie\": 86,\"Urziceni\": 98},\n","\t\t\t\t\t\t\t\t\"air_distance_to_bucharest\": 151},\n","                \"Iasi\":{\"actions\":{\"Neamt\": 87,\"Vaslui\": 92},\n","\t\t\t\t\t\t\t\t\"air_distance_to_bucharest\": 226},\n","                \"Lugoj\":{\"actions\":{\"Timisoara\": 111,\"Mehadia\": 70},\n","\t\t\t\t\t\t\t\t\"air_distance_to_bucharest\": 244},\n","                \"Mehadia\":{\"actions\":{\"Lugoj\": 70,\"Dobreta\": 75},\n","\t\t\t\t\t\t\t\t\"air_distance_to_bucharest\": 241},\n","                \"Neamt\":{\"actions\":{\"Iasi\": 87},\n","\t\t\t\t\t\t\t\t\"air_distance_to_bucharest\": 234},\n","                \"Oradea\":{\"actions\":{\"Sibiu\": 151,\"Zerind\": 71},\n","\t\t\t\t\t\t\t\t\"air_distance_to_bucharest\": 380},\n","                \"Pitesti\":{\"actions\":{\"Craiova\": 138,\"Bucharest\": 101,\"RimnicuVilcea\": 97},\n","\t\t\t\t\t\t\t\t\"air_distance_to_bucharest\": 98},\n","                \"RimnicuVilcea\":{\"actions\":{\"Craiova\": 146,\"Pitesti\": 97,\"Sibiu\": 80},\n","\t\t\t\t\t\t\t\t\"air_distance_to_bucharest\": 193},\n","                \"Sibiu\":{\"actions\":{\"Oradea\": 151,\"Arad\": 140,\"Fagaras\": 99,\"RimnicuVilcea\": 80},\n","\t\t\t\t\t\t\t\t\"air_distance_to_bucharest\": 253},\n","                \"Timisoara\":{\"actions\":{\"Arad\": 118,\"Lugoj\": 111},\n","\t\t\t\t\t\t\t\t\"air_distance_to_bucharest\": 329},\n","                \"Urziceni\":{\"actions\":{\"Hirsova\": 98,\"Bucharest\": 85,\"Vaslui\": 142},\n","\t\t\t\t\t\t\t\t\"air_distance_to_bucharest\": 80},\n","                \"Vaslui\":{\"actions\":{\"Iasi\": 92,\"Urziceni\": 142},\n","\t\t\t\t\t\t\t\t\"air_distance_to_bucharest\": 199},\n","                \"Zerind\":{\"actions\":{\"Arad\": 75,\"Oradea\": 71},\n","\t\t\t\t\t\t\t\t\"air_distance_to_bucharest\": 374}}\n","action = \"Hirsova\"\n","state = \"Arad\"\n","print (action in connections[state][\"actions\"].keys())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SEb0mRSbWbdU","executionInfo":{"status":"ok","timestamp":1696836821365,"user_tz":-120,"elapsed":364,"user":{"displayName":"Ibai Laña Aurrecoechea","userId":"16607696318122248666"}},"outputId":"0ee98804-7235-4995-d6fa-2cf263034f4a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["False\n"]}]},{"cell_type":"code","source":["spproblem = spp()\n","print(spproblem.initial_state)\n","\n","print (spproblem.get_evaluation(spproblem.initial_state))\n","print (spproblem.get_evaluation(spproblem.goal_state))"],"metadata":{"id":"PhlQJeJPtcjl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696836974483,"user_tz":-120,"elapsed":237,"user":{"displayName":"Ibai Laña Aurrecoechea","userId":"16607696318122248666"}},"outputId":"eca9d5f6-2b7d-4a34-b6ad-e082448b1413"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Arad\n","366\n","0\n"]}]},{"cell_type":"markdown","metadata":{"id":"763X7ezCjtUY"},"source":["# Expansion Function\n","Expansion function is the same as before\n","\n","\n","It receives the problem, with the functions and actions, and a NODE, which includes the following:\n","\n","* state\t(current state)\n","* parent node (parent node, starts with empty)\n","* actions (list of actions that led here)\n","* cost (starting in 0)\n","* depth (starting in 0)\n","* evaluation <----- h(n)\n","\n","\n","\n"]},{"cell_type":"code","source":["# instead of updating the frontier, the expand function only creates a list of child of possible nodes given a current node\n","# it does not receive states, but NODES, dictionaries that include other information besides state\n","def expand (node, problem):\n","    new_nodes = []\n","    possible_actions = problem.actions\n","    for action in possible_actions:\n","        if problem.is_applicable(node[\"state\"], action):\n","            new_state= problem.effect (node[\"state\"], action)\n","            new_node = {}\n","            new_node[\"state\"]=new_state\n","            new_node[\"parent_node\"]=node\n","            new_node[\"actions\"]=node[\"actions\"] + [action]\n","            new_node[\"cost\"]=node[\"cost\"] + problem.get_cost(action, node[\"state\"])\n","            new_node[\"depth\"]=node[\"depth\"]+1\n","            new_node[\"evaluation\"]=problem.get_evaluation(new_state)\n","            new_nodes.append (new_node)\n","    return new_nodes"],"metadata":{"id":"kHqvdkEWg5AO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CJ-4dc4-jubN"},"source":["# UNINFORMED SEARCH METHODS\n"]},{"cell_type":"markdown","source":["## BFS - Breadth First Search\n","\n","```\n","1. Make a node with the initial problem state\n","2. Insert node into the frontier data structure\n","3. WHILE final state not found AND frontier is not empty DO\n","  3.1 Remove first node from the frontier\n","  3.2 IF node contains final state THEN final state found\n","  3.3 IF node doesn’t contain final state THEN\n","     3.3.1 EXPAND node’s state\n","     3.3.2 Insert successor nodes into frontier\n","4. IF final state found THEN\n","  4.1  RETURN sequence of actions found\n","5. ELSE  “solution not found”\n","```\n","\n"],"metadata":{"id":"r3SQ1I7XorHU"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"k4wS7cTg1y4e"},"outputs":[],"source":["def BFS(problem):\n","    # result dictionary\n","    result = {\"method\":\"BFS\", \"final_state\":[], \"status\":\"No nodes in the frontier. No solution possible.\",\n","             \"max_frontier\":0, \"max_depth\":0, \"iterations\":0}\n","\n","    # 1. problem definition\n","    # problem = Problem()\n","    initial_node={\"state\":problem.initial_state, \"parent_node\":{}, \"actions\":[], \"cost\":0, \"depth\":0, \"evaluation\":1}\n","    frontier = []\n","\n","     # 2. add node to frontier\n","    frontier.append(initial_node)\n","\n","    # 3. start exploring and expanding the frontier\n","    iterations=1\n","    while len (frontier)>0: #if we have elements in the frontier...\n","         # 3.1. get first element of frontier and delete it\n","        node = frontier[0]\n","\n","\n","        frontier = frontier[1:]\n","        # 3.2 check if it is final state:\n","        if problem.is_final_state (node[\"state\"]):\n","            result[\"status\"]=\"Solution Found.\"\n","            break #we end while. state will remain this last state computed, and sequence of actions will have all states.\n","\n","        # 3.3 if it is not final, expand and add to the frontier\n","        new_nodes = expand(node, problem)\n","        for n in new_nodes:\n","            frontier.append(n)\n","\n","        # we compute the maximum size of frontier: the previous one or the current if it is bigger\n","        result[\"max_frontier\"]=max(result[\"max_frontier\"],len (frontier))\n","         # we compute the maximum depth: the previous one or the current if it is bigger\n","        result[\"max_depth\"]=max(result[\"max_depth\"], node[\"depth\"])\n","         # we update the iterations count\n","        result[\"iterations\"]= iterations\n","\n","        iterations+=1\n","      #loop keeps running until no more nodes available or final state obtained\n","\n","    result[\"final_state\"] = node\n","    return(result)\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"lLig9BwPXroq"},"source":["## BFS-g"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LurSJSQCZwCT"},"outputs":[],"source":["def BFS_g(problem):\n","    # result dictionary\n","    result = {\"method\":\"BFS_g\", \"final_state\":[], \"status\":\"No nodes in the frontier. No solution possible.\",\n","             \"max_frontier\":0, \"max_depth\":0, \"iterations\":0}\n","\n","    # 1. problem definition\n","    initial_node={\"state\":problem.initial_state, \"parent_node\":{}, \"actions\":[], \"cost\":0, \"depth\":0, \"evaluation\":1}\n","    frontier = []\n","\n","    ####\n","    expanded = []\n","\n","     # 2. add node to frontier\n","    frontier.append(initial_node)\n","\n","    # 3. start exploring and expanding the frontier\n","    iterations=1\n","    while len (frontier)>0: #if we have elements in the frontier...\n","         # 3.1. get first element of frontier and delete it\n","        node = frontier[0]\n","        frontier = frontier[1:]\n","\n","        #add to expanded--> we add the state, as the rest of fields will be different\n","        expanded.append(node[\"state\"])\n","\n","        # 3.2 check if it is final state:\n","        if problem.is_final_state (node[\"state\"]):\n","            result[\"status\"]=\"Solution Found.\"\n","            break #we end while. state will remain this last state computed, and sequence of actions will have all states.\n","\n","        # 3.3 if it is not final, expand and add to the frontier\n","        new_nodes = expand(node, problem)\n","        for n in new_nodes:\n","            # check if it is expanded before adding to frontier\n","            if not np.any ([np.all(n[\"state\"]== e) for e in expanded]):\n","             ##### CHANGE THE CONDITION TO FIT ALL SIZES ARRAYS::\n","             # if the state of N is not any of the elements in expanded, add to the frontier\n","            #if n[\"state\"] not in expanded:\n","                frontier.append(n)\n","\n","        # we compute the maximum size of frontier: the previous one or the current if it is bigger\n","        result[\"max_frontier\"]=max(result[\"max_frontier\"],len (frontier))\n","         # we compute the maximum depth: the previous one or the current if it is bigger\n","        result[\"max_depth\"]=max(result[\"max_depth\"], node[\"depth\"])\n","         # we update the iterations count\n","        result[\"iterations\"]= iterations\n","\n","        iterations+=1\n","      #loop keeps running until no more nodes available or final state obtained\n","\n","    result[\"final_state\"] = node\n","    return(result)"]},{"cell_type":"markdown","source":["## IDS"],"metadata":{"id":"gMlFwlsUVm-K"}},{"cell_type":"code","source":["def IDS(problem, depth_limit, iteration_limit):\n","    # result dictionary\n","    result = {\"method\":\"IDS\"+str(depth_limit), \"final_state\":[], \"status\":\"No nodes in the frontier. No solution possible.\",\n","             \"max_frontier\":0, \"max_depth\":0, \"iterations\":0}\n","\n","    # 1. problem definition\n","    initial_node={\"state\":problem.initial_state, \"parent_node\":{}, \"actions\":[], \"cost\":0, \"depth\":0, \"evaluation\":1}\n","    frontier = []\n","\n","     # 2. add node to frontier\n","    frontier.append(initial_node)\n","\n","    # 3. start exploring and expanding the frontier\n","    iterations=1\n","\n","    # we add a control of the accepted max depth, starting with 1:\n","    current_max_depth=1\n","\n","    #change the loop condition, now we have to control the end of the loop inside it\n","    while True:\n","        #if the len is 0, we have reached to the end of the depth. We start again with an increased max depth\n","        if len (frontier)==0:\n","            if current_max_depth<depth_limit:\n","                current_max_depth+=1\n","                node ={\"state\":problem.initial_state, \"parent_node\":{}, \"actions\":[], \"cost\":0, \"depth\":0, \"evaluation\":1}\n","                frontier.append(node)\n","            else:\n","                result[\"status\"]= \"No nodes in the frontier. No solution possible.\"\n","                break\n","\n","        #control if we have reached the iteration limit, stop\n","        if iterations>iteration_limit:\n","            result[\"status\"] = \"Maximum number of iterations reached\"\n","            break\n","\n","         # 3.1. get LAST element of frontier and delete it\n","        node = frontier[-1]\n","        frontier = frontier[:-1]\n","\n","        # 3.2 check if it is final state:\n","        if problem.is_final_state (node[\"state\"]):\n","            result[\"status\"]=\"Solution Found.\"\n","            break #we end while. state will remain this last state computed, and sequence of actions will have all states.\n","\n","        # 3.3 if it is not final, expand and add to the frontier\n","        new_nodes = expand(node, problem)\n","        for n in new_nodes:\n","            ##### WE ONLY APPEND IF DEPTH <= CURRENT MAX DEPTH\n","            if n[\"depth\"]<=current_max_depth:\n","                frontier.append(n)\n","            #in other case node is not appended, ending the loop\n","\n","        # we compute the maximum size of frontier: the previous one or the current if it is bigger\n","        result[\"max_frontier\"]=max(result[\"max_frontier\"],len (frontier))\n","         # we compute the maximum depth: the previous one or the current if it is bigger\n","        result[\"max_depth\"]=max(result[\"max_depth\"], node[\"depth\"])\n","         # we update the iterations count\n","        result[\"iterations\"]= iterations\n","\n","        iterations+=1\n","      #loop keeps running until no more nodes available or final state obtained\n","\n","    result[\"final_state\"] = node\n","    return(result)"],"metadata":{"id":"AzSKkKrHVs7d"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## IDS_g"],"metadata":{"id":"QlyDN3QWaUXD"}},{"cell_type":"code","source":["def IDS_g(problem, depth_limit, iteration_limit):\n","    # result dictionary\n","    result = {\"method\":\"IDS_g-\"+str(depth_limit), \"final_state\":[], \"status\":\"No nodes in the frontier. No solution possible.\",\n","             \"max_frontier\":0, \"max_depth\":0, \"iterations\":0}\n","\n","    # 1. problem definition\n","    initial_node={\"state\":problem.initial_state, \"parent_node\":{}, \"actions\":[], \"cost\":0, \"depth\":0, \"evaluation\":1}\n","    frontier = []\n","\n","    ####\n","    expanded = []\n","\n","     # 2. add node to frontier\n","    frontier.append(initial_node)\n","\n","    # 3. start exploring and expanding the frontier\n","    iterations=1\n","     # we add a control of the accepted max depth, starting with 1:\n","    current_max_depth=1\n","\n","    #change the loop condition, now we have to control the end of the loop inside it\n","    while True:\n","        #if the len is 0, we have reached to the end of the depth. We start again with an increased max depth\n","        if len (frontier)==0:\n","            if current_max_depth<depth_limit:\n","                current_max_depth+=1\n","                node ={\"state\":problem.initial_state, \"parent_node\":{}, \"actions\":[], \"cost\":0, \"depth\":0, \"evaluation\":1}\n","                frontier.append(node)\n","                expanded = []\n","            else:\n","                result[\"status\"]= \"No nodes in the frontier. No solution possible.\"\n","                break\n","       #before doing anything, if we have reached the iteration limit, stop\n","        if iterations>iteration_limit:\n","            result[\"status\"] = \"Maximum number of iterations reached\"\n","            break\n","         # 3.1. get first element of frontier and delete it\n","        node = frontier[-1]\n","        frontier = frontier[:-1]\n","\n","        #add to expanded--> we add the state, as the rest of fields will be different\n","        expanded.append(node[\"state\"])\n","\n","        # 3.2 check if it is final state:\n","        if problem.is_final_state (node[\"state\"]):\n","            result[\"status\"]=\"Solution Found.\"\n","            break #we end while. state will remain this last state computed, and sequence of actions will have all states.\n","\n","        # 3.3 if it is not final, expand and add to the frontier\n","        new_nodes = expand(node, problem)\n","        for n in new_nodes:\n","            # check if it is expanded before adding to frontier\n","            if not np.any ([np.all(n[\"state\"]== e) for e in expanded]):\n","            #if n[\"state\"] not in expanded:\n","                if n[\"depth\"]<=current_max_depth:\n","                    frontier.append(n)\n","\n","        # we compute the maximum size of frontier: the previous one or the current if it is bigger\n","        result[\"max_frontier\"]=max(result[\"max_frontier\"],len (frontier))\n","         # we compute the maximum depth: the previous one or the current if it is bigger\n","        result[\"max_depth\"]=max(result[\"max_depth\"], node[\"depth\"])\n","         # we update the iterations count\n","        result[\"iterations\"]= iterations\n","\n","        iterations+=1\n","      #loop keeps running until no more nodes available or final state obtained\n","\n","    result[\"final_state\"] = node\n","    return(result)"],"metadata":{"id":"Fe361Gc0aWqZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CObtIDslpjxQ"},"source":["# INFORMED SEARCH\n","\n","\n"]},{"cell_type":"markdown","source":["## GBFS: GREEDY BEST FIRST SEARCH\n","\n","The algorithm is equal to BFS, but in this case we add a new step, sorting the frontier in order to get the most similar node the first to be expanded.\n","\n","Besides, we need to add a control of iterations, as with other methods, as GBFS is not complete and might enter an infinite loop\n","```\n","1. Make a node with the initial problem state\n","2. Insert node into the frontier data structure\n","3. WHILE final state not found AND frontier is not empty DO\n","  3.1 Remove first node from the frontier\n","  3.2 IF node contains final state THEN final state found\n","  3.3 IF node doesn’t contain final state THEN\n","     3.3.1 EXPAND node’s state\n","     3.3.2 Insert successor nodes into frontier\n","     3.3.3 Sort frontier in ascending order of f(n)\n","4. IF final state found THEN\n","  4.1  RETURN sequence of actions found\n","5. ELSE  “solution not found”\n","```\n"],"metadata":{"id":"NOH5Rns2uWj1"}},{"cell_type":"code","source":["def GBFS(problem, iteration_limit):\n","    # result dictionary\n","    result = {\"method\":\"GBFS\", \"final_state\":[], \"status\":\"No nodes in the frontier. No solution possible.\",\n","             \"max_frontier\":0, \"max_depth\":0, \"iterations\":0}\n","\n","    # 1. problem definition\n","    # problem = Problem()\n","#####---->>>>>>> initial evaluation is obtained from the function\n","    initial_node={\"state\":problem.initial_state, \"parent_node\":{}, \"actions\":[], \"cost\":0, \"depth\":0, \"evaluation\":problem.get_evaluation(problem.initial_state)}\n","    frontier = []\n","\n","     # 2. add node to frontier\n","    frontier.append(initial_node)\n","\n","    # 3. start exploring and expanding the frontier\n","    iterations=1\n","    while len (frontier)>0: #if we have elements in the frontier...\n","\n","######---->>>>>>>> iteration control\n","        #control if we have reached the iteration limit, stop\n","        if iterations>iteration_limit:\n","            result[\"status\"] = \"Maximum number of iterations reached\"\n","            break\n","\n","         # 3.1. get first element of frontier and delete it\n","        node = frontier[0]\n","\n","\n","        frontier = frontier[1:]\n","        # 3.2 check if it is final state:\n","        if problem.is_final_state (node[\"state\"]):\n","            result[\"status\"]=\"Solution Found.\"\n","            break #we end while. state will remain this last state computed, and sequence of actions will have all states.\n","\n","        # 3.3 if it is not final, expand and add to the frontier\n","        new_nodes = expand(node, problem)\n","        for n in new_nodes:\n","            frontier.append(n)\n","\n","################# SORTING THE FRONTIER\n","        # sorting by ascending order this will lead to\n","        frontier = sorted(frontier, key=lambda field: field['evaluation'])\n","\n","        # we compute the maximum size of frontier: the previous one or the current if it is bigger\n","        result[\"max_frontier\"]=max(result[\"max_frontier\"],len (frontier))\n","         # we compute the maximum depth: the previous one or the current if it is bigger\n","        result[\"max_depth\"]=max(result[\"max_depth\"], node[\"depth\"])\n","         # we update the iterations count\n","        result[\"iterations\"]= iterations\n","\n","        iterations+=1\n","      #loop keeps running until no more nodes available or final state obtained\n","\n","    result[\"final_state\"] = node\n","    return(result)"],"metadata":{"id":"h8OTIMPWqiGa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## GBFS-Graph"],"metadata":{"id":"zFMQ8SMbtyPA"}},{"cell_type":"code","source":["def GBFS_g(problem, iteration_limit):\n","    # result dictionary\n","    result = {\"method\":\"GBFS\", \"final_state\":[], \"status\":\"No nodes in the frontier. No solution possible.\",\n","             \"max_frontier\":0, \"max_depth\":0, \"iterations\":0}\n","\n","    # 1. problem definition\n","    # problem = Problem()\n","    initial_node={\"state\":problem.initial_state, \"parent_node\":{}, \"actions\":[], \"cost\":0, \"depth\":0, \"evaluation\":problem.get_evaluation(problem.initial_state)}\n","    frontier = []\n","\n","####---->>> EXPANDED NODES LIST\n","    expanded = []\n","     # 2. add node to frontier\n","    frontier.append(initial_node)\n","\n","    # 3. start exploring and expanding the frontier\n","    iterations=1\n","    while len (frontier)>0: #if we have elements in the frontier...\n","       #control if we have reached the iteration limit, stop\n","        if iterations>iteration_limit:\n","            result[\"status\"] = \"Maximum number of iterations reached\"\n","            break\n","\n","         # 3.1. get first element of frontier and delete it\n","        node = frontier[0]\n","\n","\n","        frontier = frontier[1:]\n","        # 3.2 check if it is final state:\n","        if problem.is_final_state (node[\"state\"]):\n","            result[\"status\"]=\"Solution Found.\"\n","            break #we end while. state will remain this last state computed, and sequence of actions will have all states.\n","\n","        # 3.3 if it is not final, expand and add to the frontier\n","        new_nodes = expand(node, problem)\n","        for n in new_nodes:\n","######----->>>>>>> check if it is expanded before adding to frontier\n","            if not np.any ([np.all(n[\"state\"]== e) for e in expanded]):\n","              frontier.append(n)\n","\n","\n","        # sorting by ascending order this will lead to\n","        frontier = sorted(frontier, key=lambda field: field['evaluation'])\n","\n","        # we compute the maximum size of frontier: the previous one or the current if it is bigger\n","        result[\"max_frontier\"]=max(result[\"max_frontier\"],len (frontier))\n","         # we compute the maximum depth: the previous one or the current if it is bigger\n","        result[\"max_depth\"]=max(result[\"max_depth\"], node[\"depth\"])\n","         # we update the iterations count\n","        result[\"iterations\"]= iterations\n","\n","        iterations+=1\n","      #loop keeps running until no more nodes available or final state obtained\n","\n","    result[\"final_state\"] = node\n","    return(result)\n","\n"],"metadata":{"id":"Io6ZOImFrLKh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# COMPARISON\n"],"metadata":{"id":"AfgbYfCDvUIq"}},{"cell_type":"code","source":["problem = spp()\n","def print_results (res):\n","  print (\"METHOD: {} \\n Final_state: {} \\n Final Status: {} \\n Maximum frontier size: {}  \\n Maximum Depth: {} \\n Iterations reached: {}  \\n COST:{}\".format(res[\"method\"], res[\"final_state\"][\"actions\"], res[\"status\"], res[\"max_frontier\"], res[\"max_depth\"], res[\"iterations\"],res[\"final_state\"][\"cost\"]))\n"],"metadata":{"id":"ofyVu_1QvVto"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bfs_res = BFS(problem)\n","print_results (bfs_res)"],"metadata":{"id":"BD1YjMgjvxXv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696837060551,"user_tz":-120,"elapsed":236,"user":{"displayName":"Ibai Laña Aurrecoechea","userId":"16607696318122248666"}},"outputId":"29ed7471-746d-44a1-9d84-bcd4cd392dae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["METHOD: BFS \n"," Final_state: ['Sibiu', 'Fagaras', 'Bucharest'] \n"," Final Status: Solution Found. \n"," Maximum frontier size: 25  \n"," Maximum Depth: 3 \n"," Iterations reached: 15  \n"," COST:450\n"]}]},{"cell_type":"code","source":["bfsg_res = BFS_g(problem)\n","print_results (bfsg_res)"],"metadata":{"id":"x2k2rsQxv3_k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ids_res     = IDS(problem, depth_limit = 8, iteration_limit = 1000)\n","print_results (ids_res )"],"metadata":{"id":"5etUh75xv7b-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["idsg_res  = IDS_g(problem, depth_limit = 8, iteration_limit = 100)\n","print_results (idsg_res )\n","print (idsg_res)"],"metadata":{"id":"ZereJ3aewChk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gbfs = GBFS(problem, iteration_limit=100)\n","print_results (gbfs )"],"metadata":{"id":"oJamEr3SvspK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696837086233,"user_tz":-120,"elapsed":249,"user":{"displayName":"Ibai Laña Aurrecoechea","userId":"16607696318122248666"}},"outputId":"35f0fac0-ade3-4dd6-d65f-aa1f3e932a90"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["METHOD: GBFS \n"," Final_state: ['Sibiu', 'Fagaras', 'Bucharest'] \n"," Final Status: Solution Found. \n"," Maximum frontier size: 7  \n"," Maximum Depth: 2 \n"," Iterations reached: 3  \n"," COST:450\n"]}]},{"cell_type":"code","source":["gbfs_g= GBFS_g(problem, iteration_limit=100)\n","print_results (gbfs_g )"],"metadata":{"id":"dKD54E_-x30J"},"execution_count":null,"outputs":[]}]}